<!DOCTYPE html>
<html lang="zh">
<head>
  <meta charset="UTF-8">
  <title>중국어 TTS + MP3 저장</title>
</head>
<body>
  <h2>중국어 문장 발음 & MP3 다운로드</h2>
  <textarea id="text" rows="3" cols="40">公司同事中, 周围去外国留学的同事多吗？</textarea><br><br>

  <button id="speakBtn">읽어주기</button>
  <button id="recordBtn">읽고 MP3 저장</button>
  <a id="downloadLink" style="display:none;">MP3 다운로드</a>

  <script>
    const textArea = document.getElementById("text");
    const speakBtn = document.getElementById("speakBtn");
    const recordBtn = document.getElementById("recordBtn");
    const downloadLink = document.getElementById("downloadLink");

    // ✅ 단순 발음
    speakBtn.onclick = () => {
      const utter = new SpeechSynthesisUtterance(textArea.value);
      utter.lang = "zh-CN"; // 중국어
      speechSynthesis.speak(utter);
    };

    // ✅ 발음 + 녹음 → mp3 다운로드
    recordBtn.onclick = async () => {
      // 오디오 스트림 캡처
      const audioContext = new AudioContext();
      const dest = audioContext.createMediaStreamDestination();
      const utter = new SpeechSynthesisUtterance(textArea.value);
      utter.lang = "zh-CN";

      const synth = window.speechSynthesis;
      const source = audioContext.createMediaStreamSource(dest.stream);

      // MediaRecorder로 녹음
      const recorder = new MediaRecorder(dest.stream);
      let chunks = [];

      recorder.ondataavailable = e => chunks.push(e.data);
      recorder.onstop = e => {
        const blob = new Blob(chunks, { type: "audio/mp3" });
        const url = URL.createObjectURL(blob);
        downloadLink.href = url;
        downloadLink.download = "tts.mp3";
        downloadLink.style.display = "block";
        downloadLink.textContent = "MP3 다운로드";
      };

      recorder.start();
      synth.speak(utter);

      utter.onend = () => {
        recorder.stop();
        audioContext.close();
      };

      // 음성 합성 → 오디오 연결
      const utterSource = audioContext.createMediaStreamSource(dest.stream);
      utterSource.connect(audioContext.destination);
    };
  </script>
</body>
</html>              <label>음성/목소리</label><br/>
              <select id="voice"></select>
            </div>
            <div>
              <label>속도 <span id="rateVal" class="pill">1.0x</span></label><br/>
              <input type="range" id="rate" min="0.6" max="1.4" step="0.05" value="1.0" />
            </div>
            <div>
              <label>피치 <span id="pitchVal" class="pill">1.0</span></label><br/>
              <input type="range" id="pitch" min="0.8" max="1.2" step="0.05" value="1.0" />
            </div>
          </div>
          <div class="row" style="margin-top:16px">
            <button id="speak">원어민처럼 읽기</button>
            <button id="stop" class="sec">정지</button>
            <button id="record" class="sec" title="크롬/엣지: '이 탭 공유 및 오디오' 허용 필요">녹음하여 파일로 저장 (실험적)</button>
          </div>
          <div class="foot">※ 쉼표(，)는 짧은 쉬는 타이밍으로, 마침표(。)、물음표（？）、느낌표（！） 기준으로 문장을 분리합니다.</div>
        </div>
        <div>
          <label>대기열(문장별)</label>
          <div id="queue" class="list">문장을 입력하면 여기에 분리되어 표시됩니다.</div>
          <div class="muted" style="margin-top:6px">
            <div>• 중국어 음성이 보이지 않으면: OS/브라우저에 중국어 음성이 설치되어 있어야 합니다.</div>
            <div>• 파일 저장: 브라우저가 탭 오디오 공유를 지원할 때만 동작합니다(크롬/엣지 권장).</div>
          </div>
        </div>
      </div>
    </div>

    <p class="foot">制作者: 당신 🙂 | 오픈소스/서버리스 | GitHub Pages에 <code>index.html</code>만 올리면 끝!</p>
  </div>

  <script>
    // ---------- 유틸: 문장 분리 ----------
    function splitSentences(text){
      // 중국어 종결부호와 줄바꿈 기준으로 분리
      const parts = text
        .replace(/([。！？!?])/g, '$1\n') // 문장 끝에 줄바꿈
        .split(/\n+/)
        .map(s => s.replace(/\s+/g,'').trim()) // 공백 제거
        .filter(Boolean);
      return parts;
    }

    // ---------- 음성 목록 로드 ----------
    const voiceSel = document.getElementById('voice');
    let voices = [];
    function populateVoices(){
      voices = window.speechSynthesis.getVoices();
      const preferred = voices.filter(v => /zh|cmn|Chinese/i.test(v.lang || v.name));
      const list = preferred.length ? preferred : voices; // 중국어 우선, 없으면 전체
      voiceSel.innerHTML = '';
      list.forEach((v, i) => {
        const opt = document.createElement('option');
        opt.value = v.name;
        opt.textContent = `${v.name} (${v.lang})`;
        voiceSel.appendChild(opt);
      });
    }
    populateVoices();
    window.speechSynthesis.onvoiceschanged = populateVoices;

    // ---------- 상태 ----------
    let speaking = false;
    let stopRequested = false;

    const rateEl = document.getElementById('rate');
    const pitchEl = document.getElementById('pitch');
    const rateVal = document.getElementById('rateVal');
    const pitchVal = document.getElementById('pitchVal');
    rateEl.addEventListener('input', () => rateVal.textContent = `${Number(rateEl.value).toFixed(2)}x`);
    pitchEl.addEventListener('input', () => pitchVal.textContent = `${Number(pitchEl.value).toFixed(2)}`);

    const queueEl = document.getElementById('queue');
    const textEl = document.getElementById('text');

    function renderQueue(sentences){
      queueEl.innerHTML = sentences.map((s, idx) => `<div><span class="pill">${idx+1}</span> ${s}</div>`).join('') || '문장을 입력하면 여기에 분리되어 표시됩니다.';
    }

    textEl.addEventListener('input', () => renderQueue(splitSentences(textEl.value)));

    // ---------- 말하기 ----------
    async function speakAll(sentences){
      if(!sentences.length) return;
      speaking = true; stopRequested = false;
      for (const s of sentences){
        if(stopRequested){ break; }
        await speakOne(s);
      }
      speaking = false;
    }

    function speakOne(text){
      return new Promise(resolve => {
        const u = new SpeechSynthesisUtterance(text);
        const chosen = voices.find(v => v.name === voiceSel.value) || voices.find(v=>/zh|cmn|Chinese/i.test(v.lang||v.name)) || voices[0];
        if(chosen) u.voice = chosen;
        u.rate = Number(rateEl.value);
        u.pitch = Number(pitchEl.value);
        u.onend = resolve;
        u.onerror = resolve;
        speechSynthesis.speak(u);
      });
    }

    document.getElementById('speak').addEventListener('click', () => {
      const sentences = splitSentences(textEl.value);
      renderQueue(sentences);
      if(!sentences.length){ alert('먼저 중국어 문장을 입력해주세요.'); return; }
      if(speaking){ speechSynthesis.cancel(); speaking=false; }
      speakAll(sentences);
    });

    document.getElementById('stop').addEventListener('click', () => {
      stopRequested = true; speechSynthesis.cancel(); speaking=false;
    });

    // ---------- (실험적) 탭 오디오 녹음 → 파일 저장 ----------
    // 크롬/엣지: getDisplayMedia에서 "이 탭 공유" + "오디오" 선택 필요
    let mediaRecorder, chunks=[];
    async function startRecording(){
      // 사용자에게 탭 공유 요청 (오디오 포함)
      const stream = await navigator.mediaDevices.getDisplayMedia({
        video: true,
        audio: { echoCancellation: true, noiseSuppression: true }
      });
      // 탭만 녹음하도록 비디오 트랙은 즉시 중지하고, 오디오만 사용
      const audioTracks = stream.getAudioTracks();
      const audioStream = new MediaStream(audioTracks);
      mediaRecorder = new MediaRecorder(audioStream);
      chunks = [];
      mediaRecorder.ondataavailable = e => { if(e.data.size>0) chunks.push(e.data); };
      mediaRecorder.onstop = () => {
        const blob = new Blob(chunks, { type: 'audio/webm' });
        const url = URL.createObjectURL(blob);
        const a = document.createElement('a');
        a.href = url; a.download = `tts_zh_${Date.now()}.webm`;
        a.click();
        setTimeout(()=>URL.revokeObjectURL(url), 2000);
      };
      mediaRecorder.start();
      return stream; // 호출 측에서 stop하려고 반환
    }

    async function recordAndSpeak(){
      const sentences = splitSentences(textEl.value);
      renderQueue(sentences);
      if(!sentences.length){ alert('먼저 중국어 문장을 입력해주세요.'); return; }
      let displayStream;
      try{
        displayStream = await startRecording();
      }catch(e){
        alert('탭 오디오 공유가 허용되지 않았습니다. 크롬/엣지에서 "이 탭 공유"와 "오디오"를 켜주세요.');
        return;
      }
      // 녹음 시작 후 TTS 재생
      await speakAll(sentences);
      // 다 읽으면 녹음 정지
      if(mediaRecorder && mediaRecorder.state !== 'inactive') mediaRecorder.stop();
      // 화면 공유 중지
      displayStream.getTracks().forEach(t=>t.stop());
    }

    document.getElementById('record').addEventListener('click', recordAndSpeak);
  </script>
</body>
</html>
